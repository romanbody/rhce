# Objectives
## Manage OpenShift Container Platform
- Use the command-line interface to manage and configure an OpenShift cluster
- Use the web console to manage and configure an OpenShift cluster
- Create and delete projects
- Import, export, and configure Kubernetes resources
- Examine resources and cluster status
- View logs
- Monitor cluster events and alerts
- Troubleshoot common cluster events and alerts
- Use product documentation
## Manage users and policies
- Configure the HTPasswd identity provider for authentication
- Create and delete users
- Modify user passwords
- Modify user and group permissions
- Create and manage groups
## Control access to resources
- Define role-based access controls
- Apply permissions to users
- Create and apply secrets to manage sensitive information
- Create service accounts and apply permissions using security context constraints
## Configure networking components
- Troubleshoot software defined networking
- Create and edit external routes
- Control cluster network ingress
- Create a self signed certificate
- Secure routes using TLS certificates
## Configure pod scheduling
- Limit resource usage
- Scale applications to meet increased demand
- Control pod placement across cluster nodes
## Configure cluster scaling
- Manually control the number of cluster workers
- Automatically scale the number of cluster workers

# Solutions/Commands

## Manage OpenShift Container Platform

### Create project

```
oc new-project roman-p2
oc new-app rails-postgresql-example

oc logs postgresql-deploy

oc get all

oc get -o yaml res res.yml


oc projects

oc delete project XYZ
```

## Control access to resources

### HTPasswd
Create file:
```
htpasswd -c -B -b htpasswd.file roman roman

```
Create secret:
```
oc create secret general htpass-secret --from-file=htpasswd=htpasswd.file -n openshift-config
```

Custom resource (cr.yml):
```
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  name: cluster
spec:
  identityProviders:
  - name: my_htpasswd_provider 
    mappingMethod: claim 
    type: HTPasswd
    htpasswd:
      fileData:
        name: htpass-secret 
```

```
oc apply -f cr.yml
```

```
oc adm policy add-role-to-user admin roman
oc adm policy add-role-to-user edit roman
oc adm policy add-role-to-user view roman
oc describe rolebinding.rbac -n roman-p1
oc adm policy add-cluster-role-to-user cluster-admin roman
```

```
oc adm groups new roman-g1
oc adm groups add-users roman-g1 roman
oc adm policy add-role-to-group admin roman-g1
```

### Modify users passwd
oc extract secret/htpass-secret --to - -n openshift-config > users.htpasswd
htpasswd -B users.htpasswd roman roman2
oc create secret generic htpass-psecret --from-file=htpasswd=users.htpasswd --dry-run -o -n openshift-config | or replace -f -


### Remove users / kubeadmin

```
oc delete secrets kubeadmin -n kube-system
```

### Roles

```
oc create role podview --verb=get --resource=pod -n blue
oc create clusterrole podviewonly --verb=get --resource=pod 
```

## Secrets

### Create secrets

Create secret and import:
vim secret.yml
```
apiVersion: v1
kind: Secret
metadata:
  name: test-secret
  namespace: roman-p1
type: Opaque 
data: 
  username: dmFsdWUtMQ0K 
  password: dmFsdWUtMg0KDQo=
stringData: 
  hostname: myapp.mydomain.com 
```
oc create -f secret.yml

### Service accounts

```
oc get sa
oc create sa service-ac1
oc describe sa/service-ac1

oc policy add-role-to-user view system:serviceaccount:roman-p1:service-ac1
```

sec-cont.yml
```
kind: SecurityContextConstraints
apiVersion: security.openshift.io/v1
metadata:
  name: scc-admin
allowPrivilegedContainer: true
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
fsGroup:
  type: RunAsAny
supplementalGroups:
  type: RunAsAny
users:
- service-ac1
requiredDropCapabilities:
- KILL
- MKNOD
- SYS_CHROOT
```

## Configure networking components
- Troubleshoot software defined networking
- Create and edit external routes
- Control cluster network ingress
- Create a self signed certificate
- Secure routes using TLS certificates
## Configure pod scheduling
- Limit resource usage
- Scale applications to meet increased demand
- Control pod placement across cluster nodes
## Configure cluster scaling
- Manually control the number of cluster workers
- Automatically scale the number of cluster workers